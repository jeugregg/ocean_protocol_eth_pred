{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end example: Compare models, direct prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import libs helpers\n",
    "from helpers.ocean_helpers import calc_nmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cex_x = ccxt.binance().fetch_ohlcv('ETH/USDT', '1h')\n",
    "\n",
    "# create a Data Frame with two columns [date,eth-prices] with dates given in intervals of 1-hour\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(cex_x, columns=['date', 'open', 'max', 'min', 'close', 'volume'])\n",
    "data['date'] = pd.to_datetime(data['date'],unit='ms')\n",
    "\n",
    "# Divide the data in training and testing set. Because the data has temporal structure, we split the data in two blocks, vs. selecting randomly.\n",
    "# 90% of the data is used for training and 10 is used for testing\n",
    "train_rate = 0.9\n",
    "n = data.shape[0]\n",
    "ntrain = int(np.floor(n*train_rate))\n",
    "train_data = data.iloc[0:ntrain,:]\n",
    "test_data = data.iloc[ntrain:,:]\n",
    "\n",
    "# Create feature vectors\n",
    "# - Define how many samples in the past are used to predict future values. \n",
    "# - This also defines the number of smaples to be predicted in the future.\n",
    "max_lag = 12 \n",
    "\n",
    "# Create feature vectors with 12 columns, each representing a time-lag from the current time point\n",
    "# - That is: x(t-1), x(t-2)...x(t-12) for close and open values (different features could be grouped using the same logic)\n",
    "full_train_close = pd.concat([train_data['close'].shift(i) for i in range(0,max_lag)],axis=1).dropna().values\n",
    "full_train_open = pd.concat([train_data['open'].shift(i) for i in range(0,max_lag)],axis=1).dropna().values\n",
    "# targets are multivariate, with the values of eth from 1 - 12 hours ahead of the curent time\n",
    "y_train = full_train_close[max_lag:,:]\n",
    "# train set is lagged with respect to the targets\n",
    "x_train = np.concatenate((full_train_close[0:-max_lag,:],full_train_open[0:-max_lag,:]),axis=1)\n",
    "\n",
    "# Repeat the feature vector creation as above for the test set\n",
    "full_test_close = pd.concat([test_data['close'].shift(i) for i in range(0,max_lag)],axis=1).dropna().values\n",
    "full_test_open = pd.concat([test_data['open'].shift(i) for i in range(0,max_lag)],axis=1).dropna().values\n",
    "y_test = full_test_close[max_lag:,:]\n",
    "x_test = np.concatenate((full_test_close[0:-max_lag,:],full_test_open[0:-max_lag,:]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1579.17, 1580.87, 1575.  , 1573.34, 1570.55, 1575.36, 1574.93,\n",
       "        1583.07, 1582.98, 1584.61, 1585.66, 1588.92],\n",
       "       [1581.41, 1579.17, 1580.87, 1575.  , 1573.34, 1570.55, 1575.36,\n",
       "        1574.93, 1583.07, 1582.98, 1584.61, 1585.66],\n",
       "       [1584.89, 1581.41, 1579.17, 1580.87, 1575.  , 1573.34, 1570.55,\n",
       "        1575.36, 1574.93, 1583.07, 1582.98, 1584.61],\n",
       "       [1575.53, 1584.89, 1581.41, 1579.17, 1580.87, 1575.  , 1573.34,\n",
       "        1570.55, 1575.36, 1574.93, 1583.07, 1582.98],\n",
       "       [1575.73, 1575.53, 1584.89, 1581.41, 1579.17, 1580.87, 1575.  ,\n",
       "        1573.34, 1570.55, 1575.36, 1574.93, 1583.07],\n",
       "       [1571.53, 1575.73, 1575.53, 1584.89, 1581.41, 1579.17, 1580.87,\n",
       "        1575.  , 1573.34, 1570.55, 1575.36, 1574.93],\n",
       "       [1580.88, 1571.53, 1575.73, 1575.53, 1584.89, 1581.41, 1579.17,\n",
       "        1580.87, 1575.  , 1573.34, 1570.55, 1575.36],\n",
       "       [1617.48, 1580.88, 1571.53, 1575.73, 1575.53, 1584.89, 1581.41,\n",
       "        1579.17, 1580.87, 1575.  , 1573.34, 1570.55],\n",
       "       [1632.69, 1617.48, 1580.88, 1571.53, 1575.73, 1575.53, 1584.89,\n",
       "        1581.41, 1579.17, 1580.87, 1575.  , 1573.34],\n",
       "       [1635.23, 1632.69, 1617.48, 1580.88, 1571.53, 1575.73, 1575.53,\n",
       "        1584.89, 1581.41, 1579.17, 1580.87, 1575.  ],\n",
       "       [1637.89, 1635.23, 1632.69, 1617.48, 1580.88, 1571.53, 1575.73,\n",
       "        1575.53, 1584.89, 1581.41, 1579.17, 1580.87],\n",
       "       [1641.68, 1637.89, 1635.23, 1632.69, 1617.48, 1580.88, 1571.53,\n",
       "        1575.73, 1575.53, 1584.89, 1581.41, 1579.17],\n",
       "       [1692.5 , 1641.68, 1637.89, 1635.23, 1632.69, 1617.48, 1580.88,\n",
       "        1571.53, 1575.73, 1575.53, 1584.89, 1581.41],\n",
       "       [1675.63, 1692.5 , 1641.68, 1637.89, 1635.23, 1632.69, 1617.48,\n",
       "        1580.88, 1571.53, 1575.73, 1575.53, 1584.89],\n",
       "       [1670.22, 1675.63, 1692.5 , 1641.68, 1637.89, 1635.23, 1632.69,\n",
       "        1617.48, 1580.88, 1571.53, 1575.73, 1575.53],\n",
       "       [1671.13, 1670.22, 1675.63, 1692.5 , 1641.68, 1637.89, 1635.23,\n",
       "        1632.69, 1617.48, 1580.88, 1571.53, 1575.73],\n",
       "       [1672.82, 1671.13, 1670.22, 1675.63, 1692.5 , 1641.68, 1637.89,\n",
       "        1635.23, 1632.69, 1617.48, 1580.88, 1571.53],\n",
       "       [1670.  , 1672.82, 1671.13, 1670.22, 1675.63, 1692.5 , 1641.68,\n",
       "        1637.89, 1635.23, 1632.69, 1617.48, 1580.88],\n",
       "       [1666.54, 1670.  , 1672.82, 1671.13, 1670.22, 1675.63, 1692.5 ,\n",
       "        1641.68, 1637.89, 1635.23, 1632.69, 1617.48],\n",
       "       [1664.21, 1666.54, 1670.  , 1672.82, 1671.13, 1670.22, 1675.63,\n",
       "        1692.5 , 1641.68, 1637.89, 1635.23, 1632.69],\n",
       "       [1669.93, 1664.21, 1666.54, 1670.  , 1672.82, 1671.13, 1670.22,\n",
       "        1675.63, 1692.5 , 1641.68, 1637.89, 1635.23],\n",
       "       [1674.22, 1669.93, 1664.21, 1666.54, 1670.  , 1672.82, 1671.13,\n",
       "        1670.22, 1675.63, 1692.5 , 1641.68, 1637.89],\n",
       "       [1668.93, 1674.22, 1669.93, 1664.21, 1666.54, 1670.  , 1672.82,\n",
       "        1671.13, 1670.22, 1675.63, 1692.5 , 1641.68],\n",
       "       [1671.99, 1668.93, 1674.22, 1669.93, 1664.21, 1666.54, 1670.  ,\n",
       "        1672.82, 1671.13, 1670.22, 1675.63, 1692.5 ],\n",
       "       [1676.71, 1671.99, 1668.93, 1674.22, 1669.93, 1664.21, 1666.54,\n",
       "        1670.  , 1672.82, 1671.13, 1670.22, 1675.63],\n",
       "       [1672.62, 1676.71, 1671.99, 1668.93, 1674.22, 1669.93, 1664.21,\n",
       "        1666.54, 1670.  , 1672.82, 1671.13, 1670.22],\n",
       "       [1673.71, 1672.62, 1676.71, 1671.99, 1668.93, 1674.22, 1669.93,\n",
       "        1664.21, 1666.54, 1670.  , 1672.82, 1671.13]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 15:47:57.448960: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-02 15:47:57.449533: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-02-02 15:47:57.573915: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-02 15:47:57.856496: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-02 15:47:58.735889: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-02 15:48:15.193866: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'linreg_error_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m\n\u001b[1;32m     42\u001b[0m dnn_error \u001b[39m=\u001b[39m fit_andpredict_fcnn(x_train,y_train,x_test,y_test)\n\u001b[1;32m     45\u001b[0m \u001b[39m# Plot results\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m info \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mLR\u001b[39m\u001b[39m'\u001b[39m:linreg_error_2, \u001b[39m'\u001b[39m\u001b[39mRFR\u001b[39m\u001b[39m'\u001b[39m:rfr_error_2, \u001b[39m'\u001b[39m\u001b[39mSVR\u001b[39m\u001b[39m'\u001b[39m:svr_error_2,\u001b[39m'\u001b[39m\u001b[39mNN\u001b[39m\u001b[39m'\u001b[39m:dnn_error_2}\n\u001b[1;32m     48\u001b[0m methods \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(info\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m     49\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(info\u001b[39m.\u001b[39mvalues())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linreg_error_2' is not defined"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "\n",
    "\n",
    "# regression using a base estimator and RegressionChain\n",
    "def fit_and_predict_reg(base_model,x_train,y_train,x_test,y_test):\n",
    "  chain = RegressorChain(base_estimator=base_model).fit(x_train, y_train)  \n",
    "  yhat_test = chain.predict(x_test)\n",
    "  return calc_nmse(y_test,yhat_test)\n",
    "\n",
    "# Neural network using Keras, 2 hidden layers with RELU activations, output layer with linear activations \n",
    "def fit_andpredict_fcnn(x_train,y_train,x_test,y_test):\n",
    "  inputs = Input(shape=(x_train.shape[1],))\n",
    "  x = Dense(128,activation='relu')(inputs)\n",
    "  x = Dense(64,activation='relu')(x)\n",
    "  outputs = Dense(12,activation='linear')(x)\n",
    "  model = Model(inputs=inputs,outputs=outputs)\n",
    "  # set compiling parameters\n",
    "  model.compile( optimizer=\"adam\", loss='mean_absolute_percentage_error',metrics=[])\n",
    "  # Fit model\n",
    "  model.fit(x_train,y_train,batch_size=100, epochs=500, validation_split=0.1, verbose=0)\n",
    "  # predict\n",
    "  yhat_test = model.predict(x_test)\n",
    "  return calc_nmse(y_test,yhat_test)\n",
    "\n",
    "# multi-output linear regression\n",
    "from sklearn.linear_model import LinearRegression \n",
    "linreg = LinearRegression()\n",
    "linreg_error = fit_and_predict_reg(linreg,x_train,y_train,x_test,y_test)\n",
    "\n",
    "# multi-output random forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "rfr = RandomForestRegressor(max_depth=10)\n",
    "rfr_error = fit_and_predict_reg(rfr,x_train,y_train,x_test,y_test)\n",
    "\n",
    "# multi-output support vector machines\n",
    "from sklearn.svm import SVR\n",
    "svr = SVR(kernel='rbf', C=1000, epsilon=.1)\n",
    "svr_error = fit_and_predict_reg(svr,x_train,y_train,x_test,y_test)\n",
    "\n",
    "# Dense NN\n",
    "dnn_error = fit_andpredict_fcnn(x_train,y_train,x_test,y_test)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "\n",
    "info = {'LR':linreg_error, 'RFR':rfr_error, 'SVR':svr_error,'NN':dnn_error}\n",
    "methods = list(info.keys())\n",
    "values = list(info.values())\n",
    "  \n",
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(methods, values, color ='maroon', width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Methods\")\n",
    "plt.ylabel(\"NMSE\")\n",
    "plt.title(\"Comparison of different methods for predicting ETH value 1-12 hours ahead\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocean_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "622fbdc46093ceebca2707ee83e548aa7e8e72b315685cead53b17c59e715f82"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
